{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System for Reddit Users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem statement and data can be downloaded from this [link](https://www.kaggle.com/colemaclean/subreddit-interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import implicit\n",
    "import random\n",
    "import time\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy import stats,sparse\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "%matplotlib inline\n",
    "\n",
    "def timeit(method):\n",
    "    def timed(*args, **kw):\n",
    "        ts = time.time()\n",
    "        result = method(*args, **kw)\n",
    "        te = time.time()\n",
    "        if 'log_time' in kw:\n",
    "            name = kw.get('log_name', method.__name__.upper())\n",
    "            kw['log_time'][name] = int((te - ts) * 1000)\n",
    "        else:\n",
    "            print('%r  %2.2f ms' % \\\n",
    "                  (method.__name__, (te - ts) * 1000))\n",
    "        return result\n",
    "    return timed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    }
   ],
   "source": [
    "class reddit_rec():\n",
    "    @timeit\n",
    "    def __init__(self, path):\n",
    "        '''\n",
    "        Initialises the class, reads in the data, generates counts\n",
    "        '''\n",
    "        df = pd.read_csv(path + '/reddit_data.csv')\n",
    "        self.df = df.groupby(['username', 'subreddit'])['subreddit'].count().reset_index(name = 'counts')\n",
    "        self.n_users = self.df.username.nunique()\n",
    "        self.n_items = self.df.subreddit.nunique()\n",
    "\n",
    "        \n",
    "    def __repr__(self):\n",
    "        '''\n",
    "        Printable representation of the class \n",
    "        '''\n",
    "        repr_str = \"\\nNum. of Users: {}\\nNum of subreddits: {}\"\\\n",
    "              .format(self.n_users, self.n_items)\n",
    "        return repr_str\n",
    "    \n",
    "    \n",
    "    def _reduce_sparsity(self):\n",
    "        '''\n",
    "        Removes sparse subreddits and users\n",
    "        '''\n",
    "        # drop subreddits with less than 5 users\n",
    "        self.df = self.df[(self.df.groupby('subreddit')['username'].count() > 5).loc[self.df['subreddit']].reset_index(drop=True)]\n",
    "        self.df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # drop users with less than 5 posted subreddits\n",
    "        self.df = self.df[(self.df.groupby('username')['subreddit'].count() > 5).loc[self.df['username']].reset_index(drop=True)]\n",
    "        self.df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # Update counts\n",
    "        self.n_users = self.df.username.nunique()\n",
    "        self.n_items = self.df.subreddit.nunique()\n",
    "        return None\n",
    "    \n",
    "    def _label_encode(self):\n",
    "        '''\n",
    "        Encodes users and subreddits\n",
    "        '''\n",
    "        d = defaultdict(LabelEncoder)\n",
    "        self.df['username'] = d['username'].fit_transform(self.df['username'])\n",
    "        self.df['subreddit'] = d['subreddit'].fit_transform(self.df['subreddit'])\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def _train_test_split(self, ratings, split_count, fraction=None):\n",
    "        \"\"\"\n",
    "        Split recommendation data into train and test sets\n",
    "        \"\"\"\n",
    "        train = ratings.copy().tocoo()\n",
    "        test = ratings.copy()\n",
    "\n",
    "        if fraction:\n",
    "            try:\n",
    "                user_index = np.random.choice(\n",
    "                    np.where(np.bincount(train.row) >= split_count * 2)[0], \n",
    "                    replace=False,\n",
    "                    size=np.int32(np.floor(fraction * train.shape[0]))\n",
    "                ).tolist()\n",
    "            except:\n",
    "                print(('Not enough users with > {} '\n",
    "                      'interactions for fraction of {}')\\\n",
    "                      .format(2*k, fraction))\n",
    "                raise\n",
    "        else:\n",
    "            user_index = range(train.shape[0])\n",
    "\n",
    "        train = train.tolil()\n",
    "\n",
    "        for user in user_index:\n",
    "            test_ratings = np.random.choice(ratings.getrow(user).indices, \n",
    "                                            size=split_count, \n",
    "                                            replace=False)\n",
    "            train[user, test_ratings] = 0\n",
    "\n",
    "        test[test != 0] = 1\n",
    "        return train.tocsr(), test, user_index\n",
    "    \n",
    "    \n",
    "    @timeit\n",
    "    def preprocess(self):\n",
    "        \"\"\"\n",
    "        Performs preprocessing and train test split\n",
    "        \"\"\"\n",
    "        \n",
    "        self._reduce_sparsity()\n",
    "        self._label_encode()\n",
    "        X = csr_matrix((self.df['counts'], (self.df['username'], self.df['subreddit'])), shape=(self.n_users, self.n_items))\n",
    "        self.train, self.test, self.user_index = self._train_test_split(X, 5, fraction=0.2)\n",
    "        return self\n",
    "    \n",
    "    def _auc_score(self, predictions, test):\n",
    "        '''\n",
    "        This simple function will output the area under the curve using sklearn's metrics. \n",
    "        '''\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(test, predictions)\n",
    "        return metrics.auc(fpr, tpr)\n",
    "    \n",
    "    @timeit\n",
    "    def calc_mean_auc(self):\n",
    "        '''\n",
    "        This function will calculate the mean AUC by user for any user that had their user-item matrix altered. \n",
    "        '''\n",
    "\n",
    "        store_auc = [] # An empty list to store the AUC for each user that had an item removed from the training set\n",
    "        popularity_auc = [] # To store popular AUC scores\n",
    "        pop_items = np.array(self.test.sum(axis = 0)).reshape(-1) # Get sum of item iteractions to find most popular\n",
    "        item_vecs = csr_matrix(self.model.item_factors.T)\n",
    "        for user in self.user_index: # Iterate through each user that had an item altered\n",
    "            training_row = self.train[user,:].toarray().reshape(-1) # Get the training set row\n",
    "            zero_inds = np.where(training_row == 0) # Find where the interaction had not yet occurred\n",
    "            # Get the predicted values based on our user/item vectors\n",
    "            user_vec = csr_matrix(self.model.user_factors)[user,:]\n",
    "            pred = user_vec.dot(item_vecs).toarray()[0,zero_inds].reshape(-1)\n",
    "            # Get only the items that were originally zero\n",
    "            # Select all ratings from the MF prediction for this user that originally had no iteraction\n",
    "            actual = self.test[user,:].toarray()[0,zero_inds].reshape(-1) \n",
    "            # Select the binarized yes/no interaction pairs from the original full data\n",
    "            # that align with the same pairs in training \n",
    "            pop = pop_items[zero_inds] # Get the item popularity for our chosen items\n",
    "            store_auc.append(self._auc_score(pred, actual)) # Calculate AUC for the given user and store\n",
    "            popularity_auc.append(self._auc_score(pop, actual)) # Calculate AUC using most popular and score\n",
    "        # End users iteration\n",
    "\n",
    "        return float('%.3f'%np.mean(store_auc)), float('%.3f'%np.mean(popularity_auc))  \n",
    "       # Return the mean AUC rounded to three decimal places for both test and popularity benchmark\n",
    "    \n",
    "    @timeit\n",
    "    def train_recommender(self, alpha = 40, \n",
    "                          model = AlternatingLeastSquares(factors=20, regularization = 0.1, iterations=15)):\n",
    "        \"\"\"\n",
    "        Trains a matrix factorization based recommender system for implicit feedback datasets\n",
    "        \"\"\"\n",
    "        \n",
    "        alpha = alpha\n",
    "        # train the model on a sparse matrix of item/user/confidence weights\n",
    "        self.model = copy.deepcopy(model)\n",
    "        self.model.fit((self.train.T * alpha).astype('double'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'__init__'  9223.69 ms\n"
     ]
    }
   ],
   "source": [
    "rd = reddit_rec('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Num. of Users: 22610\n",
       "Num of subreddits: 34967"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--ANUSTART-</td>\n",
       "      <td>AOImmortals</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--ANUSTART-</td>\n",
       "      <td>Addons4Kodi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--ANUSTART-</td>\n",
       "      <td>AdviceAnimals</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--ANUSTART-</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--ANUSTART-</td>\n",
       "      <td>Assistance</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>--ANUSTART-</td>\n",
       "      <td>CombatFootage</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>--ANUSTART-</td>\n",
       "      <td>Documentaries</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>--ANUSTART-</td>\n",
       "      <td>FantasyPL</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>--ANUSTART-</td>\n",
       "      <td>FiftyFifty</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>--ANUSTART-</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      username      subreddit  counts\n",
       "0  --ANUSTART-    AOImmortals       2\n",
       "1  --ANUSTART-    Addons4Kodi       1\n",
       "2  --ANUSTART-  AdviceAnimals       7\n",
       "3  --ANUSTART-      AskReddit      14\n",
       "4  --ANUSTART-     Assistance       9\n",
       "5  --ANUSTART-  CombatFootage       1\n",
       "6  --ANUSTART-  Documentaries       1\n",
       "7  --ANUSTART-      FantasyPL       3\n",
       "8  --ANUSTART-     FiftyFifty       1\n",
       "9  --ANUSTART-        Fitness       7"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd.df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit\n",
       "AskReddit          1030290\n",
       "politics            367860\n",
       "The_Donald          216939\n",
       "nfl                 173883\n",
       "leagueoflegends     157663\n",
       "worldnews           156605\n",
       "funny               152921\n",
       "nba                 150985\n",
       "pics                143496\n",
       "news                140492\n",
       "Name: counts, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top Subreddits\n",
    "rd.df.groupby('subreddit')['counts'].sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    34967.000000\n",
       "mean        25.522979\n",
       "std        227.224157\n",
       "min          1.000000\n",
       "25%          1.000000\n",
       "50%          2.000000\n",
       "75%          7.000000\n",
       "max      14491.000000\n",
       "Name: username, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No of users posting in a subreddit\n",
    "rd.df.groupby('subreddit')['username'].count().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    22610.000000\n",
       "mean        39.472004\n",
       "std         40.855805\n",
       "min          1.000000\n",
       "25%         10.000000\n",
       "50%         28.000000\n",
       "75%         56.000000\n",
       "max        723.000000\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No of subreddits a user posts in\n",
    "rd.df.groupby('username')['subreddit'].count().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sparsity level of this dataset is 99.9%\n"
     ]
    }
   ],
   "source": [
    "sparsity=round(1.0-len(rd.df)/float(rd.n_users * rd.n_items),3)\n",
    "print('The sparsity level of this dataset is ' +  str(sparsity*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'preprocess'  4267.78 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Num. of Users: 18622\n",
       "Num of subreddits: 9645"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sparsity level of this dataset is 99.5%\n"
     ]
    }
   ],
   "source": [
    "sparsity=round(1.0-len(rd.df)/float(rd.n_users * rd.n_items),3)\n",
    "print('The sparsity level of this dataset is ' +  str(sparsity*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>388</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>408</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>980</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   username  subreddit  counts\n",
       "0         0        144       1\n",
       "1         0        160       7\n",
       "2         0        388      14\n",
       "3         0        408       9\n",
       "4         0        980       1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<18622x9645 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 818210 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The altered version of the original data with a certain percentage of the user-item pairs \n",
    "# that originally had interaction set back to zero\n",
    "rd.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<18622x9645 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 836830 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A copy of the original ratings matrix, unaltered, so it can be used to see how the rank order \n",
    "# compares with the actual interactions\n",
    "rd.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:OpenBLAS detected. Its highly recommend to set the environment variable 'export OPENBLAS_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'train_recommender'  22847.00 ms\n"
     ]
    }
   ],
   "source": [
    "rd.train_recommender(model = AlternatingLeastSquares(factors=20, regularization = 0.1, iterations=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'calc_mean_auc'  63204.82 ms\n"
     ]
    }
   ],
   "source": [
    "model_auc, pop_auc = rd.calc_mean_auc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC for our model 0.932\n",
      "Mean AUC for a popularity based model 0.897\n"
     ]
    }
   ],
   "source": [
    "print('Mean AUC for our model {}\\nMean AUC for a popularity based model {}'.format(model_auc, pop_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations\n",
    "* If you want to recommend items to a new user, it requires re-training the whole model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
